for (i in c(3,4,5,12,13,14,19,20,23,26,32,33)){
print(colnames(Ames[i]) ,cor(Ames[i], Ames$SalePrice))
}
for (i in c(3,4,5,12,13,14,19,20,23,26,32,33)){
print(paste(colnames(Ames[i]), cor(Ames[i], Ames$SalePrice)))
}
for (i in c(3,4,5,12,13,14,19,20,23,26,32,33)){
print(paste(colnames(Ames[i]), "has correlation of ", cor(Ames[i], Ames$SalePrice), "to SalePrice."))
}
for (i in c(3,4,5,12,13,14,19,20,23,26,32,33)){
print(paste(colnames(Ames[i]), "has correlation of ", round(cor(Ames[i], Ames$SalePrice), digits=3), "to SalePrice."))
}
cor(Ames[c(3,4,5,12,13,14,19,20,23,26,32,33)])
cor(Ames[ ,c(3,4,5,12,13,14,19,20,23,26,32,33)])
round(cor(Ames[ ,c(3,4,5,12,13,14,19,20,23,26,32,33)]), digits=3)
cor_matrix = round(cor(Ames[ ,c(3,4,5,12,13,14,19,20,23,26,32,33)]), digits=3)
p = ggplot(data=Ames,
mapping = aes(x=Ames$GrLivArea, y=Ames$SalePrice))
p + geom_abline() + geom_point()
p  + geom_point() + geom_abline()
library(tidyverse)
library(ggplot2)
library(scales)
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
original_options = options()
# Write NA handling exception to keep NA rows for GarageType
current_options = options(na.action='na.pass')
# Build our matrix
GarageTemp = model.matrix( ~ ameslist$GarageType - 1, data=ameslist$GarageType )
# Create our cbind and update ameslist
ameslist <- cbind(ameslist, GarageTemp)
# Restore original options
options(original_options)
int_type = lapply(ameslist, class)
# Generates a dataframe from ames data with all integer type data
Ames = ameslist[int_type=='integer']
# Drop some columns that don't have meaning
Ames$MSSubClass = NULL
# 2. Produce a scatterplot matrix of 12 variables
Scatter_Ames = pairs(Ames[,c(3,4,12,13,14,16,19,20,23,26,32,33)], pch = 19,
lower.panel = NULL)
# 3. Produce a correlation matrix of the chosen variables
# Shows correlations for our chosen variables to SalesPrice
cor_matrix = round(cor(Ames[,c(3,4,12,13,14,16,19,20,23,26,32,33)]), digits=3)
# 4. Make a scatter plot of SalePrice to GrLivArea and use abline for a linear fit
p = ggplot(data=Ames,
mapping = aes(x=Ames$GrLivArea, y=Ames$SalePrice))
# abline doesn't wanna work for me, look for fixes if you can
p + geom_abline(color='Red')  + geom_point()
View(Ames)
## This doesn't work, asking Bushong Tuesday what's up with it
ameslist$GarageOutside <- ifelse(ameslist$GarageTypeDetchd == 1 | ameslist$GarageTypeCarPort == 1, 1, 0)
# Now, we can table the new variable
table(wage2$married_factor)
# To "load" the packages, use require(...)
require(wooldridge)
# Now that you've loaded the package, you can access the data using "data"
data(wage2)
print(wage2[1:5,])
# Now, we can table the new variable
table(wage2$married_factor)
table(wage2[,'married']) #--> same as before.
# But what about NA's? We can ask R to show us any NA's as well (it doesn't by default)
table(wage2$married, useNA='always')
# Super, we have a pretty good handle on "married".
# But maybe we want to have the values be "married" and "unmarried". This is a *factor* variable.
# A *factor* variable is any variable that doesn't take a numeric form.
# we can use "as.factor" to create a married factor variable:
factor(wage2$married) #--> ok, not super helpful
factor(wage2$married, levels = c(0,1), labels = c('unmarried','married')) #--> we have to set the levels and the corresponding labels (ordering is important)
# Let's add this to our wage2 data:
wage2$married_factor = factor(wage2$married, levels=c(0,1), labels = c('unmarried','married'))
head(wage2)
# Now, we can table the new variable
table(wage2$married_factor)
# We can *also* table over more than one variable!
# We just have to pass two columns to table
table(wage2$married_factor, wage2$urban)
wage2$urban_factor = factor(wage2$urban, levels=c(0,1), labels=c('non-urban','urban'))
table(wage2[,c('married_factor','urban_factor')]) #--> we can give table a data.frame with two columns, and it will table those two
# Now, remember to only table(...) things that have only a few possible values. Tabling
# a continuous variable is going to be useless:
table(wage2$lwage)
# First, let's look at functions for mean, median:
mean(wage2$wage)
# Now, let's compute this *by group*
# What if we want the mean wage by married_factor?
# We will use aggregate(...)
require(stats)  #---> this is built in, but you might have to load it.
aggregate(wage ~ married_factor, data = wage2, FUN = mean) #--> can use "sum" or "median"...
# What if we want to do this by *multiple* groupings? urban and married?
aggregate(wage ~ married_factor + urban_factor, data=wage2, FUN=mean)
# What if we wanted multiple variables besides wage?
# We can use "cbind(...)" to the left of the ~
aggregate(cbind(wage, educ) ~ married_factor + urban_factor, data=wage2, FUN=mean)
# Some FUN's (functions) can even return multiple things, like quantile(...), by *passing* more information
aggregate(wage ~ married_factor + urban_factor, data=wage2, FUN=quantile, probs = c(.25, .5, .75)) #--> "probs" is passed through to the quantile function
# We *can* use the numeric version. When you take the mean of a binary 0/1, you get the Probability of observing 1
aggregate(married ~ urban_factor, data=wage2, FUN=mean) #--> 91.2% of rural workers are married; 88.5% of urban workers are married.
# You can, of course, save the tabled output as a data.frame:
sample1 = aggregate(married ~ urban_factor, data=wage2, FUN=mean)
print(sample1)
mean(sample1$married) #--> not sure why you'd want this, but there ya go.
hist(wage2$wage) #--> this will appear in the "plots" pane of Rstudio. When using Rmarkdown, it will be output into your document.
hist(wage2$wage, breaks=100)
plot(density(wage2$wage)) #--> density(...) returns a "density" object, which can be plotted, or printed
print(density(wage2$wage))
# A scatterplot - when you want to see the relation between x and y
# Let's look at wage and educ
plot(wage ~ educ, data=wage2)
# we can do the same without the ~
plot(x = wage2$educ, y = wage2$wage)
# What if we ask R to plot our married variable:
plot(wage ~ married, data = wage2) #--> married was just 0/1
# What if we use the *factor* version of married. Boxplot!
plot(wage ~ married_factor, data=wage2) #--> the boxplot gives the disribution. The box edges are at 25th and 75th percentile, the line is the median. The whiskers are 1.5*IQR. See: https://www.r-bloggers.com/whisker-of-boxplot/
# What if we want to include a line on our plot. Say, at the mean wage:
# We can add a second line of code that acts on the first plot(...)
plot(wage ~ educ, data=wage2)
abline(h = mean(wage2$wage), col='green') #--> added in a color!
# What if we want the regresion line? That's a bit trickier. First, we do the regression:
firstRegression = lm(wage ~ educ, wage2)
# Then, we plot the data and add a abline(...) call that uses the model we estimated:
plot(wage ~ educ, data=wage2)
abline(firstRegression, col = 'blue') #---> abline(...) knows what to do with a single variable regression!
ike what it does is double up on both ends of the overallqual
# and one of these should be dropped out.
## Lab 2
# Includes
library(tidyverse)
library(ggplot2)
library(scales)
# Read in the data set with headers TRUE
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
# Read in the data set with headers FALSE
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = FALSE,
sep = ",")
summary(ameslist)
# Notice how this clearly breaks the data by trying to force the headers to remain as part of the data. It
# forces R to structure all of this as vectors with no specific data type.
# Re-Read in the data with headers True
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
# Info on read.table
?read.table
# Get some info on the data
names(ameslist)
# Tells us the data is stored as lists instead of a data frame, something to care for later
typeof(ameslist)
# Perhaps we want to make some analysis of the garage type as a predictor for price because of the typically
# bad weather in Ames
unique(ameslist$GarageType)
# Lets further break this down into any garage that makes you walk outside, and those that don't
# First we assign values to the garage types of 0 or 1
GarageTemp = model.matrix( ~ ameslist$GarageType - 1, data=ameslist$GarageType )
# Now we stitch this back together using cbind
ameslist <- cbind(ameslist, GarageTemp)
# Lets see why this doesn't work, perhaps it's the NA values in garagetemp being dropped?
sum(is.na(ameslist$GarageType))
# Notice that the amount of NA values in GarageType is 81, and that 1379+81=1460 which is the number of rows
# we have in GarageType. So we must be dropping NA values when we make GarageTemp. Lets fix that below.
# save options default values
original_options = options()
# Write NA handling exception to keep NA rows for GarageType
current_options = options(na.action='na.pass')
# Build our matrix
GarageTemp = model.matrix( ~ ameslist$GarageType - 1, data=ameslist$GarageType )
# Create our cbind and update ameslist
ameslist <- cbind(ameslist, GarageTemp)
# Restore original options
options(original_options)
# Now we see the Bind gives us no trouble and we can change the options back so they don't mess with
# any of our later code.
unique(GarageTemp)
# Now we change our values again to indicate which of these garage types are outside
## This doesn't work, asking Bushong Tuesday what's up with it
ameslist$GarageOutside <- ifelse(ameslist$`ameslist$GarageTypeDetchd` == 1 | ameslist$`ameslist$GarageTypeCarPort` == 1, 1, 0)
unique(ameslist$GarageOutside)
vector = c(which(is.na(ameslist$GarageOutside)))
ameslist = ameslist[-c( vector ),]
unique(ameslist$GarageOutside)
## Exercise 1
# 1. Prune the data to only integers
# Generates a list of all data types for each of the columns in ameslist
int_type = lapply(ameslist, class)
# Generates a dataframe from ames data with all integer type data
Ames = ameslist[int_type=='integer']
# Drop columns that don't have meaning
Ames$MSSubClass = NULL
# 2. Produce a scatterplot matrix of 12 variables
Scatter_Ames = pairs(Ames[,c(37,3,4,12,13,14,16,19,20,23,26,32,33)], pch = 19,
lower.panel = NULL)
# 3. Produce a correlation matrix of the chosen variables
# Shows correlations for our chosen variables to SalesPrice
cor_matrix = round(cor(Ames[,c(37,3,4,12,13,14,16,19,20,23,26,32,33)]), digits=3)
# Yes this correlation matrix generally matches with my prior beleifs. Most are highly correlated meaning that they
# have a large positive effect on Sales Price. The ones with a smaller correlation still have an effect just a smaller
# effect, but still measurable
# 4. Make a scatter plot of SalePrice to GrLivArea and use abline for a linear fit
p = ggplot(data=Ames,
mapping = aes(x=Ames$GrLivArea, y=Ames$SalePrice))
j = lm(Ames$GrLivArea ~ Ames$SalePrice)
p + geom_smooth(method = lm) + geom_point()
# Modeling our data, Linear Model
attach(Ames)
lm.fit = lm(SalePrice ~ GrLivArea)
lm.fit
# GrLivArea is telling us about the size of the family room I think. It has a strong correlation with
# all of the above ground room counts, and square foot data as well.
plot(lm.fit)
lm.fit = lm(SalePrice ~ GrLivArea + LotArea)
summary(lm.fit)
plot(lm.fit)
## Exercise 2
# 1. Make a simple linear model of garage type on sale price
GOonSP = lm(SalePrice~GarageOutside, data=ameslist)
GOonSP
# 2. Full model on SalePrice
FMonSP = lm(SalePrice~., data=Ames)
summary(FMonSP)
# The largest t-value's here are are related to the general size of the house or the quality
# of the amenities. For example the poolarea tells us there is a pool and that it's
# influential on the price. Fireplaces are nearly at a t-value of 2 and the rest are all
# about size, such as rooms above ground, garage cars, and the largest being overall quality.
# Most of the variables have no real effect outside of those.
# 3. Using plot on our model
plot(GOonSP)
plot(FMonSP)
# Cooks distance so we need to investigate them further, helping to lend some validity to the argument
# for dropping them out.
# 4. Finding interaction effects.
ModifonSP = lm(SalePrice~LotArea + OverallQual + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(ModifonSP)
# Here we've slimmed down the data set to include only the points that have t-values above 2 until all values
# have this condition met. Now we will attempt to find interaction variables.
# Here we try grouping overall quality and condition to find interaction effects.
IntOQonOC = lm(SalePrice~LotArea + OverallQual*OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(IntOQonOC)
# It doesn't do so well so we will remove this and see about linking the square footage of the floots
IntX1onX2 = lm(SalePrice~LotArea + OverallQual + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + X1stFlrSF:X2ndFlrSF + BsmtFullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(IntX1onX2)
# Unfortunately this has much the same effect as before. So let's try interactions with above ground rooms
IntAbvonAbv = lm(SalePrice~LotArea + OverallQual + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
KitchenAbvGr + BedroomAbvGr:TotRmsAbvGrd+ GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(IntAbvonAbv)
# Here we may have one that works. It yields a higher F-stat than our original model and this
# makes sense because there is a direct correlation between bedrooms and total rooms above ground.
# Both of these should be and are correlated with SalePrice. So we keep this.
# 5. Let's try some transforms on the data
# Perhaps overallqual should be counted with a square since it's such a big part of buying a house.
TranXsqr = lm(SalePrice~LotArea + OverallQual + poly(OverallQual, 2) + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
KitchenAbvGr + BedroomAbvGr:TotRmsAbvGrd+ GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(TranXsqr)
# This gives a much higher F-stat and both have high t-vales so we should think of keeping this in our analysis.
TranXlog = lm(SalePrice~LotArea + OverallQual + log(OverallQual) + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
KitchenAbvGr + BedroomAbvGr:TotRmsAbvGrd+ GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(TranXlog)
# This does less well, but is still an increase, so this is something we want to explore in the data.
# What looks like is happening is the t-value is highly negative for the log while the regular variable
# has a highly positive t-value. This probably tells us that they do the same job and because we include
# them both it doubles up on them. Not what we want.
TranXsqrt = lm(SalePrice~LotArea + OverallQual + sqrt(OverallQual) + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
KitchenAbvGr + BedroomAbvGr:TotRmsAbvGrd+ GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(TranXsqrt)
# Similarly to the above value it looks like what it does is double up on both ends of the overallqual
# and one of these should be dropped out.
setwd('/Users/rileylatham/Downloads/SSC442/Practical_Lecture_Files')
p + geom_smooth(method = lm) + geom_point()
## Lab 2
# Includes
library(tidyverse)
library(ggplot2)
library(scales)
# Read in the data set with headers TRUE
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
# Read in the data set with headers FALSE
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = FALSE,
sep = ",")
summary(ameslist)
# Notice how this clearly breaks the data by trying to force the headers to remain as part of the data. It
# forces R to structure all of this as vectors with no specific data type.
# Re-Read in the data with headers True
ameslist <- read.table("https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv",
header = TRUE,
sep = ",")
# Info on read.table
?read.table
# Get some info on the data
names(ameslist)
# Tells us the data is stored as lists instead of a data frame, something to care for later
typeof(ameslist)
# Perhaps we want to make some analysis of the garage type as a predictor for price because of the typically
# bad weather in Ames
unique(ameslist$GarageType)
# Lets further break this down into any garage that makes you walk outside, and those that don't
# First we assign values to the garage types of 0 or 1
GarageTemp = model.matrix( ~ ameslist$GarageType - 1, data=ameslist$GarageType )
# Now we stitch this back together using cbind
ameslist <- cbind(ameslist, GarageTemp)
# Lets see why this doesn't work, perhaps it's the NA values in garagetemp being dropped?
sum(is.na(ameslist$GarageType))
# Notice that the amount of NA values in GarageType is 81, and that 1379+81=1460 which is the number of rows
# we have in GarageType. So we must be dropping NA values when we make GarageTemp. Lets fix that below.
# save options default values
original_options = options()
# Write NA handling exception to keep NA rows for GarageType
current_options = options(na.action='na.pass')
# Build our matrix
GarageTemp = model.matrix( ~ ameslist$GarageType - 1, data=ameslist$GarageType )
# Create our cbind and update ameslist
ameslist <- cbind(ameslist, GarageTemp)
# Restore original options
options(original_options)
# Now we see the Bind gives us no trouble and we can change the options back so they don't mess with
# any of our later code.
unique(GarageTemp)
# Now we change our values again to indicate which of these garage types are outside
## This doesn't work, asking Bushong Tuesday what's up with it
ameslist$GarageOutside <- ifelse(ameslist$`ameslist$GarageTypeDetchd` == 1 | ameslist$`ameslist$GarageTypeCarPort` == 1, 1, 0)
unique(ameslist$GarageOutside)
vector = c(which(is.na(ameslist$GarageOutside)))
ameslist = ameslist[-c( vector ),]
unique(ameslist$GarageOutside)
## Exercise 1
# 1. Prune the data to only integers
# Generates a list of all data types for each of the columns in ameslist
int_type = lapply(ameslist, class)
# Generates a dataframe from ames data with all integer type data
Ames = ameslist[int_type=='integer']
# Drop columns that don't have meaning
Ames$MSSubClass = NULL
# 2. Produce a scatterplot matrix of 12 variables
Scatter_Ames = pairs(Ames[,c(37,3,4,12,13,14,16,19,20,23,26,32,33)], pch = 19,
lower.panel = NULL)
# 3. Produce a correlation matrix of the chosen variables
# Shows correlations for our chosen variables to SalesPrice
cor_matrix = round(cor(Ames[,c(37,3,4,12,13,14,16,19,20,23,26,32,33)]), digits=3)
# Yes this correlation matrix generally matches with my prior beleifs. Most are highly correlated meaning that they
# have a large positive effect on Sales Price. The ones with a smaller correlation still have an effect just a smaller
# effect, but still measurable
# 4. Make a scatter plot of SalePrice to GrLivArea and use abline for a linear fit
p = ggplot(data=Ames,
mapping = aes(x=Ames$GrLivArea, y=Ames$SalePrice))
j = lm(Ames$GrLivArea ~ Ames$SalePrice)
p + geom_smooth(method = lm) + geom_point()
# Modeling our data, Linear Model
attach(Ames)
lm.fit = lm(SalePrice ~ GrLivArea)
lm.fit
# GrLivArea is telling us about the size of the family room I think. It has a strong correlation with
# all of the above ground room counts, and square foot data as well.
plot(lm.fit)
lm.fit = lm(SalePrice ~ GrLivArea + LotArea)
summary(lm.fit)
plot(lm.fit)
## Exercise 2
# 1. Make a simple linear model of garage type on sale price
GOonSP = lm(SalePrice~GarageOutside, data=ameslist)
GOonSP
# 2. Full model on SalePrice
FMonSP = lm(SalePrice~., data=Ames)
summary(FMonSP)
# The largest t-value's here are are related to the general size of the house or the quality
# of the amenities. For example the poolarea tells us there is a pool and that it's
# influential on the price. Fireplaces are nearly at a t-value of 2 and the rest are all
# about size, such as rooms above ground, garage cars, and the largest being overall quality.
# Most of the variables have no real effect outside of those.
# 3. Using plot on our model
plot(GOonSP)
plot(FMonSP)
# Cooks distance so we need to investigate them further, helping to lend some validity to the argument
# for dropping them out.
# 4. Finding interaction effects.
ModifonSP = lm(SalePrice~LotArea + OverallQual + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(ModifonSP)
# Here we've slimmed down the data set to include only the points that have t-values above 2 until all values
# have this condition met. Now we will attempt to find interaction variables.
# Here we try grouping overall quality and condition to find interaction effects.
IntOQonOC = lm(SalePrice~LotArea + OverallQual*OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(IntOQonOC)
# It doesn't do so well so we will remove this and see about linking the square footage of the floots
IntX1onX2 = lm(SalePrice~LotArea + OverallQual + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + X1stFlrSF:X2ndFlrSF + BsmtFullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(IntX1onX2)
# Unfortunately this has much the same effect as before. So let's try interactions with above ground rooms
IntAbvonAbv = lm(SalePrice~LotArea + OverallQual + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
KitchenAbvGr + BedroomAbvGr:TotRmsAbvGrd+ GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(IntAbvonAbv)
# Here we may have one that works. It yields a higher F-stat than our original model and this
# makes sense because there is a direct correlation between bedrooms and total rooms above ground.
# Both of these should be and are correlated with SalePrice. So we keep this.
# 5. Let's try some transforms on the data
# Perhaps overallqual should be counted with a square since it's such a big part of buying a house.
TranXsqr = lm(SalePrice~LotArea + OverallQual + poly(OverallQual, 2) + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
KitchenAbvGr + BedroomAbvGr:TotRmsAbvGrd+ GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(TranXsqr)
# This gives a much higher F-stat and both have high t-vales so we should think of keeping this in our analysis.
TranXlog = lm(SalePrice~LotArea + OverallQual + log(OverallQual) + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
KitchenAbvGr + BedroomAbvGr:TotRmsAbvGrd+ GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(TranXlog)
# This does less well, but is still an increase, so this is something we want to explore in the data.
# What looks like is happening is the t-value is highly negative for the log while the regular variable
# has a highly positive t-value. This probably tells us that they do the same job and because we include
# them both it doubles up on them. Not what we want.
TranXsqrt = lm(SalePrice~LotArea + OverallQual + sqrt(OverallQual) + OverallCond + YearBuilt +
MasVnrArea + BsmtFinSF1 + X1stFlrSF + X2ndFlrSF + BsmtFullBath +
KitchenAbvGr + BedroomAbvGr:TotRmsAbvGrd+ GarageCars + WoodDeckSF +
ScreenPorch, data=Ames)
summary(TranXsqrt)
# Similarly to the above value it looks like what it does is double up on both ends of the overallqual
# and one of these should be dropped out.
# Simulation stuff
sim_1 = function(sample_size = 500) {
x = runif(n = sample_size) * 5
y = 3 + 5 * x + rnorm(n = sample_size, mean = 0, sd = 1)
data.frame(x, y)
}
sim_2 = function(sample_size = 500) {
x = runif(n = sample_size) * 5
y = 3 + 5 * x + rnorm(n = sample_size, mean = 0, sd = x)
data.frame(x, y)
}
sim_3 = function(sample_size = 500) {
x = runif(n = sample_size) * 5
y = 3 + 5 * x ^ 2 + rnorm(n = sample_size, mean = 0, sd = 5)
data.frame(x, y)
}
set.seed(42)
sim_data_1 = sim_1()
head(sim_data_1)
plot(y ~ x, data = sim_data_1, col = "grey", pch = 20,
main = "Data from Model 1")
fit_1 = lm(y ~ x, data = sim_data_1)
abline(fit_1, col = "darkorange", lwd = 3)
plot(y ~ x, data = sim_data_1, col = "grey", pch = 20,
main = "Data from Model 1")
fit_1 = lm(y ~ x, data = sim_data_1)
abline(fit_1, col = "darkorange", lwd = 3)
# Plot our sim 1 and make linear model
plot(y ~ x, data = sim_data_1, col = "grey", pch = 20,
main = "Data from Model 1")
# Simulation stuff
sim_1 = function(sample_size = 500) {
x = runif(n = sample_size) * 5
y = 3 + 5 * x + rnorm(n = sample_size, mean = 0, sd = 1)
data.frame(x, y)
}
sim_2 = function(sample_size = 500) {
x = runif(n = sample_size) * 5
y = 3 + 5 * x + rnorm(n = sample_size, mean = 0, sd = x)
data.frame(x, y)
}
sim_3 = function(sample_size = 500) {
x = runif(n = sample_size) * 5
y = 3 + 5 * x ^ 2 + rnorm(n = sample_size, mean = 0, sd = 5)
data.frame(x, y)
}
# Runing sim 1
set.seed(42)
sim_data_1 = sim_1()
head(sim_data_1)
# Plot our sim 1 and make linear model
plot(y ~ x, data = sim_data_1, col = "grey", pch = 20,
main = "Data from Model 1")
fit_1 = lm(y ~ x, data = sim_data_1)
abline(fit_1, col = "darkorange", lwd = 3)
plot(fitted(fit_1), resid(fit_1), col = "grey", pch = 20,
xlab = "Fitted", ylab = "Residuals", main = "Data from Model 1")
abline(h = 0, col = "darkorange", lwd = 2)
plot(fitted(fit_1), resid(fit_1), col = "grey", pch = 20,
xlab = "Fitted", ylab = "Residuals", main = "Data from Model 1")
abline(h = 0, col = "darkorange", lwd = 2)
